{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Numerically solving ODEs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ODE definition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An ordinary differential equation (ODE) describes the rate of change of a function $y(x)$ with respect to an independent variable $x$ and the function value itself.\n",
    "\n",
    "The general form of a first-order ODE is:\n",
    "$$\n",
    "y' = f(x, y)\n",
    "$$\n",
    "\n",
    "Moreover, higher-order ODEs can be transformed into a system of first-order ODEs. Therefore, it is often beneficial to focus on solving first-order ODEs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solving ODEs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To obtain a unique solution of the ODE, an initial condition, typically $y(x_0) = y_0$, is required to select a specific solution from a family of possible solutions. This is known as an initial value problem (IVP).\n",
    "\n",
    "For complex ODEs where an analytical solution is not feasible, numerical methods can be employed to approximate the solution accurately. These methods are particularly useful for solving initial value problems (IVPs) where exact solutions are difficult or impossible to derive."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sampled functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In math, a function $y(x)$ maps a real number $x$ to a real value $y(x)$. But for computers, a function is defined at discrete points $x_k$, a process known as discretization.\n",
    "\n",
    "ODE solvers compute solutions at these discrete points, resulting in a vector of values $y_k$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Error analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Taylor's series expansion for error analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Taylor series expansion of a function $f(x)$ around the point $x_0$ (the expansion center) with a single independent variable $x$ is given by:\n",
    "$$\n",
    "f(x) = f(x_0) + (x - x_0) \\left.\\frac{df}{dx}\\right|_{x_0} + \\frac{(x - x_0)^2}{2!} \\left.\\frac{d^2f}{dx^2}\\right|_{x_0} + \\frac{(x - x_0)^3}{3!} \\left.\\frac{d^3f}{dx^3}\\right|_{x_0} + \\ldots + \\frac{(x - x_0)^p}{p!} \\left.\\frac{d^pf}{dx^p}\\right|_{x_0}\n",
    "$$\n",
    "\n",
    "The Taylor series expansion can be used to verify the accuracy of numerical approximations by comparing the terms of the infinite series with the finite approximations.\n",
    "\n",
    "The error itself is usually expressed using the $O(h)$-notation, where all terms of order $h$ and higher are neglected. The power of $h$ in the $O(h)$-notation corresponds to the power of $h$ where the first term in the infinite Taylor series that is not included in the finite approximation appears."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Derivative truncation error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The derivative approximation truncation error  $\\tau_h^{(n)}(x)$ of a order $n$ derivative $f^{(n)}$ can be expressed as:\n",
    "$$\n",
    "\\tau_h^{(n)}(x) = f_\\text{approx}^{(n)}(x) - f_\\text{Taylor}^{(n)}(x)\n",
    "$$\n",
    "\n",
    "Or if the actual derivative gets approximated with Taylor's series:\n",
    "$$\n",
    "f_\\text{Taylor}^{(n)}(x) = f_\\text{approx}^{(n)}(x) - \\tau_h^{(n)}(x)\n",
    "$$\n",
    "\n",
    "The $O(h)$-notation can be expressed from the $\\tau_h^{(n)}(x)$ term, since this term is the error-term of the approximation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Differentiation on the computer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before solving differential equations on a computer, it's important to understand how differentiation is approximated. The derivative of a function $y(x)$ is defined as:\n",
    "$$\n",
    "\\frac{dy}{dx} = \\lim_{\\Delta x \\to 0} \\frac{y(x + \\Delta x) - y(x)}{\\Delta x}\n",
    "$$\n",
    "In numerical computation, this limit cannot be directly represented because data is usually discrete and floating-point numbers do not approach zero smoothly. Instead, derivatives are approximated using finite differences.\n",
    "\n",
    "($\\Delta x$ is often denoted as the step size $h$ in the context of numerical differentiation.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finite derivatives from Taylor's series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Forward difference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Express $y(x + h)$ with $x_0 = x$ using Taylor's series expansion:\n",
    "$$\n",
    "y(x + h) = y(x) + h \\left.\\frac{dy}{dx}\\right|_{x} + \\frac{h^2}{2!} \\left.\\frac{d^2y}{dx^2}\\right|_{x} + \\frac{h^3}{3!} \\left.\\frac{d^3y}{dx^3}\\right|_{x} + \\ldots + \\frac{h^p}{p!} \\left.\\frac{d^py}{dx^p}\\right|_{x}\n",
    "$$\n",
    "\n",
    "Solve for the first derivative of $y(x)$ and make the assumption that $h$ is very small $\\to$ terms with power of $h$ and higher are errors:\n",
    "\n",
    "(only the term with the lowest power of $h$ is considered to be the leading order error term)\n",
    "\n",
    "$$\n",
    "\\frac{dy}{dx} = \\frac{y(x + h) - y(x)}{h} - \\underbrace{\\frac{h}{2} \\left.\\frac{d^2y}{dx^2}\\right|_{x}}_{\\substack{\\text{leading order} \\\\ \\text{error term}}} - \\frac{h^2}{6} \\left.\\frac{d^3y}{dx^3}\\right|_{x} - \\ldots - \\frac{h^{p-1}}{p!} \\left.\\frac{d^py}{dx^p}\\right|_{x}\n",
    "$$\n",
    "\n",
    "Describe the first derivative of $y(x)$ with $O(h)$ as the leading error term, where the error is proportional to $h$ and higher-order terms are neglected:\n",
    "$$\n",
    "\\frac{dy}{dx} = \\frac{y(x + h) - y(x)}{h} + O(h)\n",
    "$$\n",
    "In this case, the forward difference approximation introduces an error proportional to $h$, while this error decreases as $h$ approaches zero, it remains present in computations with finite $h$, scaling as $O(h)$.\n",
    "\n",
    "Remove the error term to obtain the forward difference approximation:\n",
    "$$\n",
    "\\boxed{\n",
    "    \\frac{dy}{dx} \\approx \\frac{y(x + h) - y(x)}{h}\n",
    "}\\quad\\text{Forward difference formula}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Backward difference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Express $y(x - h)$ with $x_0 = x$ using Taylor's series expansion:\n",
    "$$\n",
    "y(x - h) = y(x) - h \\left.\\frac{dy}{dx}\\right|_{x} + \\frac{h^2}{2!} \\left.\\frac{d^2y}{dx^2}\\right|_{x} - \\frac{h^3}{3!} \\left.\\frac{d^3y}{dx^3}\\right|_{x} + \\ldots + (-1)^p \\frac{h^p}{p!} \\left.\\frac{d^py}{dx^p}\\right|_{x}\n",
    "$$\n",
    "\n",
    "Solve for the first derivative of $y(x)$ and make the assumption that $h$ is very small $\\to$ terms with power of $h$ and higher are errors:\n",
    "\n",
    "(only the term with the lowest power of $h$ is considered to be the leading order error term)\n",
    "\n",
    "$$\n",
    "\\frac{dy}{dx} = \\frac{y(x) - y(x - h)}{h} - \\underbrace{\\frac{h}{2} \\left.\\frac{d^2y}{dx^2}\\right|_{x}}_{\\substack{\\text{leading order} \\\\ \\text{error term}}} - \\frac{h^2}{6} \\left.\\frac{d^3y}{dx^3}\\right|_{x} - \\ldots - \\frac{h^{p-1}}{p!} \\left.\\frac{d^py}{dx^p}\\right|_{x}\n",
    "$$\n",
    "\n",
    "Describe the first derivative of $y(x)$ with $O(h)$ as the leading error term, where the error is proportional to $h$ and higher-order terms are neglected:\n",
    "$$\n",
    "\\frac{dy}{dx} = \\frac{y(x) - y(x - h)}{h} + O(h)\n",
    "$$\n",
    "\n",
    "In this case, the backward difference approximation introduces an error proportional to $h$, while this error decreases as $h$ approaches zero, it remains present in computations with finite $h$, scaling as $O(h)$.\n",
    "\n",
    "Remove the error term to obtain the backward difference approximation:\n",
    "$$\n",
    "\\boxed{\n",
    "    \\frac{dy}{dx} \\approx \\frac{y(x) - y(x - h)}{h}\n",
    "}\\quad\\text{Backward difference formula}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Central difference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finding expression to cancel the leading order error term of order $h$ in forward and backward difference approximations.\n",
    "$$\n",
    "y(x+h) - y(x-h) = 2h\\left.\\frac{dy}{dx}\\right|_{x} + \\frac{2h^3}{6}\\left.\\frac{d^3y}{dx^3}\\right|_{x} + \\ldots + \\frac{2h^p}{p!}\\left.\\frac{d^py}{dx^p}\\right|_{x} \\quad (p\\hat{=}\\text{odd})\n",
    "$$\n",
    "\n",
    "Solve for the first derivative of $y(x)$:\n",
    "$$\n",
    "\\frac{dy}{dx} = \\frac{y(x+h) - y(x-h)}{2h} - \\underbrace{\\frac{h^2}{3}\\left.\\frac{d^3y}{dx^3}\\right|_{x}}_{\\substack{\\text{leading order} \\\\ \\text{error term}}} - \\frac{h^3}{12}\\left.\\frac{d^4y}{dx^4}\\right|_{x} - \\ldots - \\frac{h^{p-1}}{2 p!}\\left.\\frac{d^py}{dx^p}\\right|_{x} \\quad (p\\hat{=} \\text{odd})\n",
    "$$\n",
    "\n",
    "Describe the first derivative of $y(x)$ with $O(h^2)$ as the leading order error term, where the error is proportional to $h^2$ and higher-order terms are neglected:\n",
    "$$\n",
    "\\frac{dy}{dx} = \\frac{y(x+h) - y(x-h)}{2h} + O(h^2)\n",
    "$$\n",
    "\n",
    "In this case, the central difference approximation introduces an error proportional to $h^2$. While this error decreases as $h$ approaches zero, it remains present in computations with finite $h$, scaling as $O(h^2)$.\n",
    "\n",
    "The central difference formula, by discarding $O(h^2)$ terms, incurs a smaller truncation error than the $O(h)$ error in forward or backward differences, making it a more accurate method.\n",
    "\n",
    "Remove the error term to obtain the central difference approximation:\n",
    "$$\n",
    "\\boxed{\n",
    "    \\frac{dy}{dx} \\approx \\frac{y(x+h) - y(x-h)}{2h}\n",
    "} \\quad \\text{Central difference formula}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Second derivative"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build sum of Forward and Backward difference approximations:\n",
    "$$\n",
    "y(x + h) + y(x - h) = 2y(x) + h^2 \\frac{d^2y}{dx^2} + \\frac{h^4}{4!} \\frac{d^4y}{dx^4} + \\frac{h^6}{6!} \\frac{d^6y}{dx^6} + \\ldots + \\frac{h^{p}}{p!} \\frac{d^py}{dx^p}\\quad (p\\hat{=}\\text{even})\n",
    "$$\n",
    "\n",
    "Solve for the second derivative of $y(x)$:\n",
    "$$\n",
    "\\frac{d^2y}{dx^2} = \\frac{y(x + h) - 2y(x) + y(x - h)}{h^2} - \\underbrace{\\frac{h^2}{4!} \\frac{d^4y}{dx^4}}_{\\substack{\\text{leading order} \\\\ \\text{error term}}} - \\frac{h^4}{6!} \\frac{d^6y}{dx^6} - \\ldots - \\frac{h^{p-2}}{p!} \\frac{d^py}{dx^p}\\quad (p\\hat{=}\\text{even})\n",
    "$$\n",
    "\n",
    "Describe the second derivative of $y(x)$ with $O(h^2)$ as the leading error term, where the error is proportional to $h^2$ and higher-order terms are neglected:\n",
    "$$\n",
    "\\frac{d^2y}{dx^2} = \\frac{y(x + h) - 2y(x) + y(x - h)}{h^2} + O(h^2)\n",
    "$$\n",
    "\n",
    "In this case, the finite second derivative formula introduces an error proportional to $h^2$. While this error decreases as $h$ approaches zero, it remains present in computations with finite $h$, scaling as $O(h^2)$.\n",
    "\n",
    "Remove the error term to obtain the finite second derivative formula:\n",
    "$$\n",
    "\\boxed{\n",
    "    \\frac{d^2y}{dx^2} \\approx \\frac{y(x + h) - 2y(x) + y(x - h)}{h^2}\n",
    "}\\quad\\text{Finite second derivative formula}\n",
    "$$\n",
    "\n",
    "Since the $O(h^2)$ terms are neglected, an error of $O(h^2)$ is introduced."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Application in games"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Solving ODEs is a fundamental concept in game development. ODEs are used to model the behaviour of physical systems, such as the movement of a character, the motion of a projectile, the behaviour of a vehicle, etc.\n",
    "\n",
    "But in this case the independent variable is time and the ODEs are described by physical laws."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Where to start?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First of all, almost every game has a game loop. This game loop includes an update phase where the physics of the game states are calculated and the ODEs are solved. Depending on the structure of the game loop, the update phase is called more or less frequently. The shorter the time between updates, the more accurate the simulation becomes.\n",
    "\n",
    "The game state is stored as variables in the program, and the ODEs are solved at each update. The $\\Delta t$-variable represents the small step $h$ of the ODEs and is calculated by taking the difference between the timestamps of the current and the previous update.\n",
    "\n",
    "Once the current game state and the $\\Delta t$-variable are known, the ODEs can be solved using numerical solvers/integrators."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
